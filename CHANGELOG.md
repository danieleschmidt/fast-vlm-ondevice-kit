# Changelog

All notable changes to Fast VLM On-Device Kit will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- Initial repository structure with comprehensive SDLC foundation
- Python package structure with pyproject.toml configuration
- Swift package for iOS integration
- Core ML conversion pipeline architecture
- Comprehensive documentation structure
- Pre-commit hooks with security scanning
- Testing framework with pytest and coverage
- Code quality tools (black, isort, mypy, flake8, bandit)
- Essential project governance files

### Security
- Bandit security scanning in pre-commit hooks
- Dependency vulnerability monitoring setup
- Secure coding practices documentation

## [1.0.0] - TBD

### Added
- FastVLM PyTorch to Core ML converter
- iOS Swift package for on-device inference
- Quantization optimization (INT4/INT8/FP16)
- Apple Neural Engine optimization
- Comprehensive benchmarking suite
- Production-ready mobile deployment examples

### Performance
- <250ms inference latency on iPhone 15 Pro
- Optimized memory usage (<1GB peak)
- Apple Neural Engine utilization
- Batch processing support

### Documentation
- Complete API documentation  
- Architecture overview and design decisions
- Performance benchmarking results
- iOS integration examples
- Deployment guides